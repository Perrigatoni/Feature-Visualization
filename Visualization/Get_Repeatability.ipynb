{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel\\anaconda3\\envs\\torchCUDA\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet18, ResNet18_Weights, resnet34\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1', 'layer1.0.conv1', 'layer1.0.conv2', 'layer1.1.conv1', 'layer1.1.conv2', 'layer1.2.conv1', 'layer1.2.conv2', 'layer2.0.conv1', 'layer2.0.conv2', 'layer2.1.conv1', 'layer2.1.conv2', 'layer2.2.conv1', 'layer2.2.conv2', 'layer2.3.conv1', 'layer2.3.conv2', 'layer3.0.conv1', 'layer3.0.conv2', 'layer3.1.conv1', 'layer3.1.conv2', 'layer3.2.conv1', 'layer3.2.conv2', 'layer3.3.conv1', 'layer3.3.conv2', 'layer3.4.conv1', 'layer3.4.conv2', 'layer3.5.conv1', 'layer3.5.conv2', 'layer4.0.conv1', 'layer4.0.conv2', 'layer4.1.conv1', 'layer4.1.conv2', 'layer4.2.conv1', 'layer4.2.conv2', 'fc']\n"
     ]
    }
   ],
   "source": [
    "weights = None  # ResNet18_Weights.DEFAULT\n",
    "model = resnet34(weights=weights)\n",
    "\n",
    "# reshape last layer.\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, 10)\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\Noel\\Documents\\THESIS\\Feature Visualization\\Weights\\resnet34_torchvision\\test72_epoch446.pth\"))\n",
    "# Set model to evaluation mode and send to device\n",
    "model.to(device).eval()\n",
    "\n",
    "layers_of_interest = [name for name, _ in model.named_modules() if \"conv\" in name or \"fc\" in name]\n",
    "\n",
    "print(layers_of_interest)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell works, but is technically wrong and would not 'fly' if the notebook was to be converted to an actual python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_activations = {}\n",
    "\n",
    "# def hook_wrapper(name: str):\n",
    "#     def hook_fn(module: nn.Module, input: torch.Tensor, output: torch.Tensor) -> None:\n",
    "#         layer_activations[name] = output\n",
    "#     return hook_fn\n",
    "\n",
    "\n",
    "# for name, layer in model.named_modules():\n",
    "#     if name in layers_of_interest:\n",
    "#         layer.register_forward_hook(hook_wrapper(name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To combat this, I made the hooks into objects of a hook class, holding both the output and the hook function, thus creating dictionary entries \n",
    "of a key/value pair of name/Hook_Layer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([<__main__.Hook_Layer object at 0x000002DB35D05120>, <__main__.Hook_Layer object at 0x000002DB35D06EF0>, <__main__.Hook_Layer object at 0x000002DB35D064A0>, <__main__.Hook_Layer object at 0x000002DB35D06320>, <__main__.Hook_Layer object at 0x000002DB35D06230>, <__main__.Hook_Layer object at 0x000002DB35D060E0>, <__main__.Hook_Layer object at 0x000002DB35D05F60>, <__main__.Hook_Layer object at 0x000002DB35D05690>, <__main__.Hook_Layer object at 0x000002DB35D05630>, <__main__.Hook_Layer object at 0x000002DB35D06590>, <__main__.Hook_Layer object at 0x000002DB35D066B0>, <__main__.Hook_Layer object at 0x000002DB35D06830>, <__main__.Hook_Layer object at 0x000002DB35D06950>, <__main__.Hook_Layer object at 0x000002DB35D06A70>, <__main__.Hook_Layer object at 0x000002DB35D06BF0>, <__main__.Hook_Layer object at 0x000002DB35D06D10>, <__main__.Hook_Layer object at 0x000002DB35D07A30>, <__main__.Hook_Layer object at 0x000002DB35D07C70>, <__main__.Hook_Layer object at 0x000002DB35D07D30>, <__main__.Hook_Layer object at 0x000002DB35D07DF0>, <__main__.Hook_Layer object at 0x000002DB35D07FA0>, <__main__.Hook_Layer object at 0x000002DB35D07850>, <__main__.Hook_Layer object at 0x000002DB35D072E0>, <__main__.Hook_Layer object at 0x000002DB35D07190>, <__main__.Hook_Layer object at 0x000002DB35D070A0>, <__main__.Hook_Layer object at 0x000002DB35D04F70>, <__main__.Hook_Layer object at 0x000002DB35D04E20>, <__main__.Hook_Layer object at 0x000002DB35D042E0>, <__main__.Hook_Layer object at 0x000002DB35D05DB0>, <__main__.Hook_Layer object at 0x000002DB35D07730>, <__main__.Hook_Layer object at 0x000002DB2ABD1DE0>, <__main__.Hook_Layer object at 0x000002DB2ABD0BB0>, <__main__.Hook_Layer object at 0x000002DB2ABD1270>, <__main__.Hook_Layer object at 0x000002DB2ABD0A90>, <__main__.Hook_Layer object at 0x000002DB2ABD0490>, <__main__.Hook_Layer object at 0x000002DB2ABD3D30>, <__main__.Hook_Layer object at 0x000002DB2ABD3EB0>])\n"
     ]
    }
   ],
   "source": [
    "class Hook_Layer():\n",
    "    def __init__(self, layer) -> None:\n",
    "        self.hook = layer.register_forward_hook(self.hook_fn)\n",
    "        self.output = None\n",
    "\n",
    "    def hook_fn(self, layer, input, output):\n",
    "        self.output = output\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.output\n",
    "\n",
    "layer_activations = {}\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        layer_activations[name] = Hook_Layer(layer)\n",
    "\n",
    "print(layer_activations.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset class that extends ImageFolder while\n",
    "# simultaneously returning a 3 way Tuple, instead of the\n",
    "# original that contains 2 elements.\n",
    "# For that reason we must define a new __getitem__ method.\n",
    "class ImageFolderWithPaths(ImageFolder):\n",
    "    \"\"\"Dataset class extending ImageFolder dataset,\n",
    "        returning Tuple.\n",
    "        \n",
    "        Returns:\n",
    "                Tuple[img[torch.Tensor],\n",
    "                      label[int],\n",
    "                      path[str]]\n",
    "        \"\"\"\n",
    "    def __getitem__(self, index: int):\n",
    "        # Super the __getitem__ of base class\n",
    "        img, label = super().__getitem__(index)\n",
    "        # Extract the path of each image in the dataset\n",
    "        path = self.imgs[index][0]\n",
    "        # Return new tuple with 3 elements\n",
    "        return (img, label, path)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader Initialized. Note that workers > 1 cannot be specified when not in main.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 262/262 [06:44<00:00,  1.54s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "\n",
    "transforms = T.Compose([T.Resize(224),\n",
    "                        # T.CenterCrop(224),\n",
    "                        T.ToTensor(),\n",
    "                        T.Normalize([0.5162, 0.4644, 0.3975],\n",
    "                                    [0.2724, 0.2640, 0.2574])\n",
    "                        ])\n",
    "\n",
    "dataset = ImageFolderWithPaths(root=r\"C:\\Users\\Noel\\Documents\\THESIS\\Outputs_Feature_Visualization\\test72outputs\",\n",
    "                               transform=transforms)\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "print(\"Dataloader Initialized. Note that workers > 1 cannot be specified when not in main.\")\n",
    "# ================================================================\n",
    "data = [] # list of dicts to be filled with dicts...\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, label, paths in tqdm(dataloader, total=len(dataloader)):\n",
    "        # Send stuff to GPU if available.\n",
    "        images = images.to(device)\n",
    "        label = label.to(device)\n",
    "        # Make Forward Pass.\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        # path_list = []\n",
    "        # for path in paths:\n",
    "        #     path_list.append(path)\n",
    "        \n",
    "        for i, image in enumerate(images):\n",
    "            private_dict = {}\n",
    "            # Three entries regarding the image identification.\n",
    "            # private_dict['path'] = path_list[i]\n",
    "            private_dict['path'] = paths[i]\n",
    "            private_dict['layer'] = label[i].item()\n",
    "            private_dict['prediction'] = preds[i].item()\n",
    "            # Iterate over all available layers.\n",
    "            for key, hook_object in layer_activations.items():\n",
    "                tensor_out = hook_object()  # .output  # modified from original script to accommodate objects \n",
    "                if key == 'fc':\n",
    "                    # The array to store is a 32 by 10 array, each batch\n",
    "                    output = torch.unbind(tensor_out, dim=0)\n",
    "                else:\n",
    "                    # The array will have a final shape of 32 by num_channels\n",
    "                    # in specific layer\n",
    "                    b, c, _, _ = tensor_out.shape\n",
    "                    output = torch.unbind(tensor_out.view(b, c, -1).mean(2), dim=0)\n",
    "                private_dict[key] = output[i].cpu().numpy()\n",
    "            data.append(private_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, copy=False)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(r\"C:\\Users\\Noel\\Documents\\THESIS\\Feature Visualization\\Dataframes\\reapeatability_resnet34.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>layer</th>\n",
       "      <th>prediction</th>\n",
       "      <th>conv1</th>\n",
       "      <th>layer1.0.conv1</th>\n",
       "      <th>layer1.0.conv2</th>\n",
       "      <th>layer1.1.conv1</th>\n",
       "      <th>layer1.1.conv2</th>\n",
       "      <th>layer1.2.conv1</th>\n",
       "      <th>layer1.2.conv2</th>\n",
       "      <th>...</th>\n",
       "      <th>layer3.5.conv1</th>\n",
       "      <th>layer3.5.conv2</th>\n",
       "      <th>layer4.0.conv1</th>\n",
       "      <th>layer4.0.conv2</th>\n",
       "      <th>layer4.0.downsample.0</th>\n",
       "      <th>layer4.1.conv1</th>\n",
       "      <th>layer4.1.conv2</th>\n",
       "      <th>layer4.2.conv1</th>\n",
       "      <th>layer4.2.conv2</th>\n",
       "      <th>fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16763</th>\n",
       "      <td>C:\\Users\\Noel\\Documents\\THESIS\\Outputs_Feature...</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.00096876634, 0.114484824, -0.04415039, -0.0...</td>\n",
       "      <td>[-0.057529658, -0.063573174, 0.038570747, 0.03...</td>\n",
       "      <td>[-0.008665042, -0.0071253264, -0.0025478743, -...</td>\n",
       "      <td>[0.0007617282, -0.015230497, -0.003674686, -0....</td>\n",
       "      <td>[-0.0032790632, -4.3875396e-05, -0.0003813878,...</td>\n",
       "      <td>[-0.012611017, -0.0005725565, -0.0104052825, -...</td>\n",
       "      <td>[-0.0039874683, -0.0008782879, -0.0023062448, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.0033337115, -0.0027309558, -0.006235859, -...</td>\n",
       "      <td>[0.0005360425, -9.052953e-05, -0.0021928581, -...</td>\n",
       "      <td>[0.0026599306, 0.025986698, 0.010221425, -0.00...</td>\n",
       "      <td>[-0.0027279442, 0.0022271308, -2.4134255e-05, ...</td>\n",
       "      <td>[-0.00267472, -0.0027023633, -0.0010572865, -0...</td>\n",
       "      <td>[0.003845722, 0.0023889209, -0.00022369532, -0...</td>\n",
       "      <td>[-0.005443983, 0.0054930556, 0.0013585001, -0....</td>\n",
       "      <td>[-0.030245243, -0.014614122, 0.00019472624, -0...</td>\n",
       "      <td>[-0.007139252, 0.008308258, 0.00093443657, 9.3...</td>\n",
       "      <td>[-2.0899808, 7.1576595, -1.6357356, 0.185611, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16764</th>\n",
       "      <td>C:\\Users\\Noel\\Documents\\THESIS\\Outputs_Feature...</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0011316112, 0.103750035, -0.026638087, -0.0...</td>\n",
       "      <td>[-0.059302013, -0.06850745, 0.04201432, 0.0321...</td>\n",
       "      <td>[-0.008857502, -0.007807972, -0.002084257, -0....</td>\n",
       "      <td>[0.00080051523, -0.01521659, -0.0036875526, -0...</td>\n",
       "      <td>[-0.0035028323, -0.00029173162, -0.00086190103...</td>\n",
       "      <td>[-0.013251992, -0.0015560512, -0.009748482, -0...</td>\n",
       "      <td>[-0.004242531, -0.00091371575, -0.0022335786, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.012142185, -0.010446279, -0.02594975, -0.0...</td>\n",
       "      <td>[-0.0011639284, 0.0006540309, -0.004402735, -0...</td>\n",
       "      <td>[0.017940098, 0.058991026, 0.032060556, -0.000...</td>\n",
       "      <td>[0.0048445384, -0.024306469, -0.002932472, 0.0...</td>\n",
       "      <td>[-0.010082682, -0.011240369, -0.0037485347, 0....</td>\n",
       "      <td>[0.11149411, 0.079004765, -0.09613093, 0.10035...</td>\n",
       "      <td>[-0.024657998, -0.027079722, -0.011865776, 0.0...</td>\n",
       "      <td>[0.0042196717, 0.094611324, 0.12524557, 0.0765...</td>\n",
       "      <td>[-0.036866132, -0.019842548, -0.018178288, 0.0...</td>\n",
       "      <td>[-0.6999701, -1.7772549, 6.829746, -4.4503675,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16765</th>\n",
       "      <td>C:\\Users\\Noel\\Documents\\THESIS\\Outputs_Feature...</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.0001686031, -0.044705294, 0.038685407, 0.0...</td>\n",
       "      <td>[-0.050312568, -0.0669264, 0.039513994, 0.0240...</td>\n",
       "      <td>[-0.007111615, -0.0045274147, -0.0019259733, -...</td>\n",
       "      <td>[0.0012283836, -0.014501246, -0.0038110767, -0...</td>\n",
       "      <td>[-0.0034099142, -0.0003029082, -0.0007221217, ...</td>\n",
       "      <td>[-0.010378127, 0.00044186704, -0.009007157, -0...</td>\n",
       "      <td>[-0.006328371, -0.0012991672, -0.0021493915, -...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0057261027, -0.029653726, 0.013501534, -0.0...</td>\n",
       "      <td>[0.00396108, 0.009770911, -0.025450194, -0.032...</td>\n",
       "      <td>[-0.02280678, -0.051518936, -0.043059252, -0.0...</td>\n",
       "      <td>[0.061880767, 0.15515295, 0.033979557, -0.0028...</td>\n",
       "      <td>[0.020194318, 0.06499129, 0.010237767, -0.0079...</td>\n",
       "      <td>[-0.10511552, -0.062572956, -0.12431853, -0.35...</td>\n",
       "      <td>[0.044749025, 0.11800861, 0.022330768, 0.00354...</td>\n",
       "      <td>[-0.25621364, -0.40510118, -0.20398428, -0.126...</td>\n",
       "      <td>[0.025166823, 0.06821161, 0.009425057, 0.00052...</td>\n",
       "      <td>[-2.2767293, -3.6783912, -1.3631047, 16.932001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16766</th>\n",
       "      <td>C:\\Users\\Noel\\Documents\\THESIS\\Outputs_Feature...</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>[-1.0849307e-05, -0.018928057, 0.015330843, 0....</td>\n",
       "      <td>[-0.04425906, -0.05638759, 0.031417742, 0.0236...</td>\n",
       "      <td>[-0.0051782485, -0.0027342706, -0.0016419498, ...</td>\n",
       "      <td>[0.0020780987, -0.013625809, -0.0018170886, -0...</td>\n",
       "      <td>[-0.0027625882, -0.00021597916, -0.0002880661,...</td>\n",
       "      <td>[-0.00941255, 0.0006703108, -0.009750235, -0.0...</td>\n",
       "      <td>[-0.0043701907, -0.00060331787, -0.001960252, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.02635998, -0.030668037, -0.04729579, -0.01...</td>\n",
       "      <td>[-0.004548288, 0.006140421, -0.022189068, -0.0...</td>\n",
       "      <td>[-0.017954288, -0.023509398, -0.02389037, -0.0...</td>\n",
       "      <td>[-0.01211678, -0.014070711, -0.0033538754, 0.0...</td>\n",
       "      <td>[-0.009657426, -0.0068088933, -0.0010294435, 0...</td>\n",
       "      <td>[0.25229046, 0.04529514, -0.0115074515, 0.0872...</td>\n",
       "      <td>[-0.0074387137, -0.0118736075, -0.0059353607, ...</td>\n",
       "      <td>[-0.11042725, 0.0126648825, 0.18875137, -0.061...</td>\n",
       "      <td>[-0.007405166, -0.011222391, -0.007097958, -0....</td>\n",
       "      <td>[-0.8872853, -3.0202978, 13.517811, -1.9300402...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16767</th>\n",
       "      <td>C:\\Users\\Noel\\Documents\\THESIS\\Outputs_Feature...</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0008869492, 0.09791261, -0.03274804, -0.001...</td>\n",
       "      <td>[-0.062553786, -0.07473618, 0.04509284, 0.0356...</td>\n",
       "      <td>[-0.009970991, -0.008687125, -0.0027372246, -0...</td>\n",
       "      <td>[-0.0001685373, -0.016996153, -0.005166251, -0...</td>\n",
       "      <td>[-0.004345696, -0.0007345782, -0.0008021509, 0...</td>\n",
       "      <td>[-0.01278695, -0.0015975254, -0.010177558, -0....</td>\n",
       "      <td>[-0.0051451614, -0.0010368845, -0.002497496, -...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.0034679314, -0.011886271, -0.012954271, -0...</td>\n",
       "      <td>[-0.00020555747, -0.00083503645, 0.0024039836,...</td>\n",
       "      <td>[0.034745414, 0.07398399, 0.045501474, -0.0019...</td>\n",
       "      <td>[0.026242305, -0.009406382, 0.0058208704, 0.04...</td>\n",
       "      <td>[-0.0068017268, -0.007461292, -0.0031480752, 0...</td>\n",
       "      <td>[-0.027689628, 0.10125272, -0.12365723, 0.0410...</td>\n",
       "      <td>[-0.014088189, -0.016056605, -0.0052886903, 0....</td>\n",
       "      <td>[0.026039792, 0.054989513, -0.013113658, 0.117...</td>\n",
       "      <td>[-0.021108357, -0.0030894552, -0.010504253, 0....</td>\n",
       "      <td>[-1.8031869, -3.1033545, -0.26437572, -3.74675...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path  layer  prediction  \\\n",
       "16763  C:\\Users\\Noel\\Documents\\THESIS\\Outputs_Feature...     35           1   \n",
       "16764  C:\\Users\\Noel\\Documents\\THESIS\\Outputs_Feature...     35           2   \n",
       "16765  C:\\Users\\Noel\\Documents\\THESIS\\Outputs_Feature...     35           3   \n",
       "16766  C:\\Users\\Noel\\Documents\\THESIS\\Outputs_Feature...     35           2   \n",
       "16767  C:\\Users\\Noel\\Documents\\THESIS\\Outputs_Feature...     35           8   \n",
       "\n",
       "                                                   conv1  \\\n",
       "16763  [0.00096876634, 0.114484824, -0.04415039, -0.0...   \n",
       "16764  [0.0011316112, 0.103750035, -0.026638087, -0.0...   \n",
       "16765  [-0.0001686031, -0.044705294, 0.038685407, 0.0...   \n",
       "16766  [-1.0849307e-05, -0.018928057, 0.015330843, 0....   \n",
       "16767  [0.0008869492, 0.09791261, -0.03274804, -0.001...   \n",
       "\n",
       "                                          layer1.0.conv1  \\\n",
       "16763  [-0.057529658, -0.063573174, 0.038570747, 0.03...   \n",
       "16764  [-0.059302013, -0.06850745, 0.04201432, 0.0321...   \n",
       "16765  [-0.050312568, -0.0669264, 0.039513994, 0.0240...   \n",
       "16766  [-0.04425906, -0.05638759, 0.031417742, 0.0236...   \n",
       "16767  [-0.062553786, -0.07473618, 0.04509284, 0.0356...   \n",
       "\n",
       "                                          layer1.0.conv2  \\\n",
       "16763  [-0.008665042, -0.0071253264, -0.0025478743, -...   \n",
       "16764  [-0.008857502, -0.007807972, -0.002084257, -0....   \n",
       "16765  [-0.007111615, -0.0045274147, -0.0019259733, -...   \n",
       "16766  [-0.0051782485, -0.0027342706, -0.0016419498, ...   \n",
       "16767  [-0.009970991, -0.008687125, -0.0027372246, -0...   \n",
       "\n",
       "                                          layer1.1.conv1  \\\n",
       "16763  [0.0007617282, -0.015230497, -0.003674686, -0....   \n",
       "16764  [0.00080051523, -0.01521659, -0.0036875526, -0...   \n",
       "16765  [0.0012283836, -0.014501246, -0.0038110767, -0...   \n",
       "16766  [0.0020780987, -0.013625809, -0.0018170886, -0...   \n",
       "16767  [-0.0001685373, -0.016996153, -0.005166251, -0...   \n",
       "\n",
       "                                          layer1.1.conv2  \\\n",
       "16763  [-0.0032790632, -4.3875396e-05, -0.0003813878,...   \n",
       "16764  [-0.0035028323, -0.00029173162, -0.00086190103...   \n",
       "16765  [-0.0034099142, -0.0003029082, -0.0007221217, ...   \n",
       "16766  [-0.0027625882, -0.00021597916, -0.0002880661,...   \n",
       "16767  [-0.004345696, -0.0007345782, -0.0008021509, 0...   \n",
       "\n",
       "                                          layer1.2.conv1  \\\n",
       "16763  [-0.012611017, -0.0005725565, -0.0104052825, -...   \n",
       "16764  [-0.013251992, -0.0015560512, -0.009748482, -0...   \n",
       "16765  [-0.010378127, 0.00044186704, -0.009007157, -0...   \n",
       "16766  [-0.00941255, 0.0006703108, -0.009750235, -0.0...   \n",
       "16767  [-0.01278695, -0.0015975254, -0.010177558, -0....   \n",
       "\n",
       "                                          layer1.2.conv2  ...  \\\n",
       "16763  [-0.0039874683, -0.0008782879, -0.0023062448, ...  ...   \n",
       "16764  [-0.004242531, -0.00091371575, -0.0022335786, ...  ...   \n",
       "16765  [-0.006328371, -0.0012991672, -0.0021493915, -...  ...   \n",
       "16766  [-0.0043701907, -0.00060331787, -0.001960252, ...  ...   \n",
       "16767  [-0.0051451614, -0.0010368845, -0.002497496, -...  ...   \n",
       "\n",
       "                                          layer3.5.conv1  \\\n",
       "16763  [-0.0033337115, -0.0027309558, -0.006235859, -...   \n",
       "16764  [-0.012142185, -0.010446279, -0.02594975, -0.0...   \n",
       "16765  [0.0057261027, -0.029653726, 0.013501534, -0.0...   \n",
       "16766  [-0.02635998, -0.030668037, -0.04729579, -0.01...   \n",
       "16767  [-0.0034679314, -0.011886271, -0.012954271, -0...   \n",
       "\n",
       "                                          layer3.5.conv2  \\\n",
       "16763  [0.0005360425, -9.052953e-05, -0.0021928581, -...   \n",
       "16764  [-0.0011639284, 0.0006540309, -0.004402735, -0...   \n",
       "16765  [0.00396108, 0.009770911, -0.025450194, -0.032...   \n",
       "16766  [-0.004548288, 0.006140421, -0.022189068, -0.0...   \n",
       "16767  [-0.00020555747, -0.00083503645, 0.0024039836,...   \n",
       "\n",
       "                                          layer4.0.conv1  \\\n",
       "16763  [0.0026599306, 0.025986698, 0.010221425, -0.00...   \n",
       "16764  [0.017940098, 0.058991026, 0.032060556, -0.000...   \n",
       "16765  [-0.02280678, -0.051518936, -0.043059252, -0.0...   \n",
       "16766  [-0.017954288, -0.023509398, -0.02389037, -0.0...   \n",
       "16767  [0.034745414, 0.07398399, 0.045501474, -0.0019...   \n",
       "\n",
       "                                          layer4.0.conv2  \\\n",
       "16763  [-0.0027279442, 0.0022271308, -2.4134255e-05, ...   \n",
       "16764  [0.0048445384, -0.024306469, -0.002932472, 0.0...   \n",
       "16765  [0.061880767, 0.15515295, 0.033979557, -0.0028...   \n",
       "16766  [-0.01211678, -0.014070711, -0.0033538754, 0.0...   \n",
       "16767  [0.026242305, -0.009406382, 0.0058208704, 0.04...   \n",
       "\n",
       "                                   layer4.0.downsample.0  \\\n",
       "16763  [-0.00267472, -0.0027023633, -0.0010572865, -0...   \n",
       "16764  [-0.010082682, -0.011240369, -0.0037485347, 0....   \n",
       "16765  [0.020194318, 0.06499129, 0.010237767, -0.0079...   \n",
       "16766  [-0.009657426, -0.0068088933, -0.0010294435, 0...   \n",
       "16767  [-0.0068017268, -0.007461292, -0.0031480752, 0...   \n",
       "\n",
       "                                          layer4.1.conv1  \\\n",
       "16763  [0.003845722, 0.0023889209, -0.00022369532, -0...   \n",
       "16764  [0.11149411, 0.079004765, -0.09613093, 0.10035...   \n",
       "16765  [-0.10511552, -0.062572956, -0.12431853, -0.35...   \n",
       "16766  [0.25229046, 0.04529514, -0.0115074515, 0.0872...   \n",
       "16767  [-0.027689628, 0.10125272, -0.12365723, 0.0410...   \n",
       "\n",
       "                                          layer4.1.conv2  \\\n",
       "16763  [-0.005443983, 0.0054930556, 0.0013585001, -0....   \n",
       "16764  [-0.024657998, -0.027079722, -0.011865776, 0.0...   \n",
       "16765  [0.044749025, 0.11800861, 0.022330768, 0.00354...   \n",
       "16766  [-0.0074387137, -0.0118736075, -0.0059353607, ...   \n",
       "16767  [-0.014088189, -0.016056605, -0.0052886903, 0....   \n",
       "\n",
       "                                          layer4.2.conv1  \\\n",
       "16763  [-0.030245243, -0.014614122, 0.00019472624, -0...   \n",
       "16764  [0.0042196717, 0.094611324, 0.12524557, 0.0765...   \n",
       "16765  [-0.25621364, -0.40510118, -0.20398428, -0.126...   \n",
       "16766  [-0.11042725, 0.0126648825, 0.18875137, -0.061...   \n",
       "16767  [0.026039792, 0.054989513, -0.013113658, 0.117...   \n",
       "\n",
       "                                          layer4.2.conv2  \\\n",
       "16763  [-0.007139252, 0.008308258, 0.00093443657, 9.3...   \n",
       "16764  [-0.036866132, -0.019842548, -0.018178288, 0.0...   \n",
       "16765  [0.025166823, 0.06821161, 0.009425057, 0.00052...   \n",
       "16766  [-0.007405166, -0.011222391, -0.007097958, -0....   \n",
       "16767  [-0.021108357, -0.0030894552, -0.010504253, 0....   \n",
       "\n",
       "                                                      fc  \n",
       "16763  [-2.0899808, 7.1576595, -1.6357356, 0.185611, ...  \n",
       "16764  [-0.6999701, -1.7772549, 6.829746, -4.4503675,...  \n",
       "16765  [-2.2767293, -3.6783912, -1.3631047, 16.932001...  \n",
       "16766  [-0.8872853, -3.0202978, 13.517811, -1.9300402...  \n",
       "16767  [-1.8031869, -3.1033545, -0.26437572, -3.74675...  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(r\"C:\\Users\\Noel\\Documents\\THESIS\\Feature Visualization\\Dataframes\\reapeatability_resnet34.parquet\")\n",
    "df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchCUDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18ff6e8b2fd13bf6d8a6c622bd97b42372209098e930592ee4b22e7c3c3c40a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
