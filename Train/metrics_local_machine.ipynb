{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a 10x10 confusion matrix the values for True Positive, True Negative and False Positive, False Negative are a bit more confusingly placed than those regarding a simpler binary classification task. \n",
    "</br>\n",
    "**True_Positive** : Is the singular value regarding a class label. For example, for class 6, the True Positive value is the cell at indices [5,5].\n",
    "</br>\n",
    "**True_Negative** : Is everything else on the confusion matrix that isn't on the line and column of the True Positive Value. In our specific example, everything except row 5 and column 5 is part of True Negative and has to be sum'ed.\n",
    "</br>\n",
    "**False_Positive** : Everything on the previously ignored column (with the exception of the correct value for TP) is called False Positive.\n",
    "</br>\n",
    "**False_Negative** : Everything on the previously ignored row  (with the exception of the value for TP) is called False Negative."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*As it might have become obvious by now, we have to calculate all these scores for all of the 10 classes in our dataset. That means each class will in the end have their own PRecision, Recall and F1-score.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "df = pd.read_parquet(path=r\"C:\\Users\\Noel\\Documents\\THESIS\\Feature Visualization\\Dataframes\\df_confmat_test65\")\n",
    "# print(df)\n",
    "\n",
    "conf_mat = df.to_numpy()\n",
    "# print(conf_mat)\n",
    "# indices = ['art_nouveau', 'baroque', 'expressionism', 'impressionism',\n",
    "#                'post_impressionism.', 'realism', 'renaissance', 'romanticism',\n",
    "#                'surrealism', 'ukiyo_e']\n",
    "# confusion_plot = ConfusionMatrixDisplay(conf_mat,\n",
    "#                                     display_labels=indices\n",
    "#                                     )\n",
    "# confusion_plot.plot(xticks_rotation='vertical',\n",
    "#                 colorbar=False)\n",
    "Mean_Acc = 0\n",
    "for i in range(len(conf_mat)):\n",
    "    Mean_Acc += conf_mat[i, i] / 1000\n",
    "# print(f\"Mean Accuracy: {(Mean_Acc * 10):.4f} %\")\n",
    "class_score_dict = {}\n",
    "for class_label in range(len(conf_mat)):\n",
    "\n",
    "    TP = conf_mat[class_label, class_label]\n",
    "    temp_conf = np.copy(conf_mat)\n",
    "    temp_conf[class_label, class_label] = 0\n",
    "    FP = sum(temp_conf[:, class_label])\n",
    "    FN = sum(temp_conf[class_label, :])\n",
    "\n",
    "    temp_conf = np.copy(conf_mat)\n",
    "    temp_conf[:, class_label] = 0\n",
    "    temp_conf[class_label, :] = 0\n",
    "\n",
    "    TN = sum(sum(temp_conf))\n",
    "    # TN = np.mean(temp_conf)  # Same operation...\n",
    "    \n",
    "\n",
    "    # Calculate scores and save them to dictionary\n",
    "    Precision = TP / (TP + FP)\n",
    "    Recall = TP / (TP + FN)\n",
    "    F1 = (Precision * Recall / (Precision + Recall)) * 2 \n",
    "\n",
    "    class_score_dict[class_label] = (Precision, Recall, F1)\n",
    "\n",
    "# Save the confmat as figure too.\n",
    "# confusion_plot.figure_.savefig(f'bestconfmat_test65.png',\n",
    "#                         bbox_inches='tight')\n",
    "\n",
    "# for key, value in class_score_dict.items():\n",
    "#     print(f'Class {key}: Precision:{value[0]:.4f}, Recall:{value[1]:.4f}, F1-Score:{value[2]:.4f}')\n",
    "\n",
    "df = pd.DataFrame.from_dict(class_score_dict)\n",
    "df.columns = [f\"class {n}\" for n in range(0,10)]\n",
    "df.index = [\"Precision\", \"Recall\", \"F1-Score\"]\n",
    "df.head()\n",
    "df.to_csv(\"Metrics_test65_to_excel.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchCUDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
